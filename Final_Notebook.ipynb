{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# Important Links\n",
    "# https://github.com/allanbreyes/udacity-data-science/tree/master/p4\n",
    "# https://github.com/seifip/udacity-data-analyst-nanodegree/tree/master/P5%20-%20Identifying%20Fraud%20from%20Enron%20Emails%20and%20Financial%20Data\n",
    "# https://www.civisanalytics.com/blog/workflows-in-python-using-pipeline-and-gridsearchcv-for-more-compact-and-comprehensive-code/\n",
    "# http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "# http://www.datasciencecentral.com/profiles/blogs/feature-scaling-and-normalization\n",
    "# http://www.programcreek.com/python/example/82501/sklearn.preprocessing.MinMaxScaler\n",
    "# https://www.analyticsvidhya.com/blog/2016/07/practical-guide-data-preprocessing-python-scikit-learn/\n",
    "# https://powerbi.microsoft.com/en-us/guided-learning/powerbi-learning-3-11h-r-visual-integration/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import pandas\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import *\n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "features_list = ['poi']\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "    \n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # enron_df = pandas.DataFrame.from_dict(my_dataset)\n",
    "# for i in data_dict.values():\n",
    "#     plt.scatter( i['salary'] , i['total_payments']  )\n",
    "\n",
    "# plt.xlabel(\"salary\")\n",
    "# plt.ylabel(\"total_payments\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # plt.show()\n",
    "# for k, v in data_dict.items():\n",
    "#     if v['salary'] != 'NaN' and v['salary'] > 1111258: print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in data_dict.values():\n",
    "#     plt.scatter( i['salary'] , i['bonus']  )\n",
    "\n",
    "# plt.xlabel(\"salary\")\n",
    "# plt.ylabel(\"bonus\")\n",
    "# plt.show()\n",
    "\n",
    "# # there is an extreme outlier\n",
    "\n",
    "\n",
    "\n",
    "# # turns out to be the TOTAL row from the salaries & as.read_csv(\"enron.csv\")\n",
    "# # enron_df.head()bonuses list, let's remove it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data_dict[\"TOTAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Communication:\n",
    "for item in my_dataset:\n",
    "    person = my_dataset[item]\n",
    "    if (all([person['from_poi_to_this_person'] != 'NaN',\n",
    "             person['from_this_person_to_poi'] != 'NaN',\n",
    "             person['to_messages'] != 'NaN',\n",
    "             person['from_messages'] != 'NaN'\n",
    "            ])):\n",
    "        fraction_from_poi = float(person[\"from_poi_to_this_person\"]) / float(person[\"to_messages\"])\n",
    "        person[\"fraction_from_poi\"] = fraction_from_poi\n",
    "        fraction_to_poi = float(person[\"from_this_person_to_poi\"]) / float(person[\"from_messages\"])\n",
    "        person[\"fraction_to_poi\"] = fraction_to_poi\n",
    "    else:\n",
    "        person[\"fraction_from_poi\"] = person[\"fraction_to_poi\"] = 0\n",
    "\n",
    "# ## Financial:\n",
    "for item in my_dataset:\n",
    "    person = my_dataset[item]\n",
    "    if (all([person['salary'] != 'NaN',\n",
    "             person['total_stock_value'] != 'NaN',\n",
    "             person['exercised_stock_options'] != 'NaN',\n",
    "             person['bonus'] != 'NaN'\n",
    "            ])):\n",
    "        person['wealth'] = sum([person[field] for field in ['salary',\n",
    "                                                            'total_stock_value',\n",
    "                                                            'exercised_stock_options',\n",
    "                                                            'bonus']])\n",
    "    else:\n",
    "        person['wealth'] = 'NaN'\n",
    "\n",
    "my_features = features_list + ['fraction_from_poi',\n",
    "                               'fraction_to_poi',\n",
    "                               'shared_receipt_with_poi',\n",
    "                               'expenses',\n",
    "                               'loan_advances',\n",
    "                               'long_term_incentive',\n",
    "                               'other',\n",
    "                               'restricted_stock',\n",
    "                               'restricted_stock_deferred',\n",
    "                               'deferral_payments',\n",
    "                               'deferred_income',\n",
    "                               'salary',\n",
    "                               'total_stock_value',\n",
    "                               'exercised_stock_options',\n",
    "                               'total_payments',\n",
    "                               'bonus',\n",
    "                               'wealth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, my_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07451757,  0.02961276,  0.25484514, ...,  0.04330293,\n",
       "         0.521875  ,  0.08561095],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.00176194,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.31703443,  0.        ,  0.08422387, ...,  0.00884703,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.00347915,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.00053203,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Scale features\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intuitive features: ['poi', 'fraction_from_poi', 'fraction_to_poi', 'shared_receipt_with_poi', 'expenses', 'loan_advances', 'long_term_incentive', 'other', 'restricted_stock', 'restricted_stock_deferred', 'deferral_payments', 'deferred_income', 'salary', 'total_stock_value', 'exercised_stock_options', 'total_payments', 'bonus', 'wealth']\n"
     ]
    }
   ],
   "source": [
    "print \"Intuitive features:\", my_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('feature_selection', SelectKBest(k=3, score_func=<function f_classif at 0x7ff60d37bb90>)), ('GaussianNB', GaussianNB(priors=None))])\n",
      "(True, 'bonus', 29.081491199795181)\n",
      "(True, 'salary', 15.119692725298126)\n",
      "(True, 'fraction_to_poi', 12.89761482372556)\n",
      "(False, 'total_stock_value', 10.374045713087989)\n",
      "(False, 'shared_receipt_with_poi', 9.8582776246375587)\n",
      "(False, 'exercised_stock_options', 9.6305853837525035)\n",
      "(False, 'wealth', 8.9660211199691791)\n",
      "(False, 'total_payments', 8.5140956287314875)\n",
      "(False, 'long_term_incentive', 8.1194130541475662)\n",
      "(False, 'deferred_income', 7.9221360027191352)\n",
      "(False, 'restricted_stock', 7.5855209858935693)\n",
      "(False, 'loan_advances', 6.7057870201376479)\n",
      "(False, 'expenses', 3.8744660455757707)\n",
      "(False, 'other', 2.9463988912624939)\n",
      "(False, 'restricted_stock_deferred', 0.71324401933397774)\n",
      "(False, 'fraction_from_poi', 0.37577092640120102)\n",
      "(False, 'deferral_payments', 0.019933736026878885)\n",
      "\n",
      "GaussianNB(priors=None)\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.93      0.92        43\n",
      "        1.0       0.25      0.20      0.22         5\n",
      "\n",
      "avg / total       0.84      0.85      0.85        48\n",
      "\n",
      "\n",
      "0.854166666667\n"
     ]
    }
   ],
   "source": [
    "select = SelectKBest()\n",
    "# pca = PCA(n_components = 7)\n",
    "clf = GaussianNB()\n",
    "\n",
    "steps = [('feature_selection', select),\n",
    "        ('GaussianNB', clf)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# d_features = pca.fit_transform(features_train)\n",
    "# ds_features = pca.transform(features_test)\n",
    "\n",
    "### and print the report\n",
    "parameters = dict(feature_selection__k = [3,4,5])\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters, cv = 10)\n",
    "\n",
    "### fit your pipeline on features_train and labels_train\n",
    "cv.fit(features_train, labels_train)\n",
    "\n",
    "### call pipeline.predict() on your features_test data to make a set of test predictions\n",
    "pred = cv.predict(features_test)\n",
    "\n",
    "### test your predictions using sklearn.classification_report()\n",
    "report = classification_report(labels_test, pred)\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "\n",
    "results = pandas.DataFrame.from_dict(cv.cv_results_)\n",
    "\n",
    "results_list = zip(cv.best_estimator_.named_steps['feature_selection'].get_support(), my_features[1:],\n",
    "                   cv.best_estimator_.named_steps['feature_selection'].scores_)\n",
    "\n",
    "results_list = sorted(results_list, key = lambda x: x[2], reverse=True)\n",
    "\n",
    "print(cv.best_estimator_)\n",
    "\n",
    "best_scores = cv.best_estimator_.named_steps['feature_selection'].scores_\n",
    "best_scores = sorted([round(x, 3) for x in best_scores], reverse = True)\n",
    "\n",
    "# print best_scores\n",
    "# results_list\n",
    "# print results\n",
    "for i in results_list: print i\n",
    "print '\\n',cv.best_estimator_.steps[1][1]\n",
    "print'\\n',report\n",
    "print '\\n', accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('feature_selection', SelectKBest(k=5, score_func=<function f_classif at 0x7ff60d37bb90>)), ('random_forest', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07,...mators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])\n",
      "(True, 'bonus', 29.081491199795181)\n",
      "(True, 'salary', 15.119692725298126)\n",
      "(True, 'fraction_to_poi', 12.89761482372556)\n",
      "(True, 'total_stock_value', 10.374045713087989)\n",
      "(True, 'shared_receipt_with_poi', 9.8582776246375587)\n",
      "(False, 'exercised_stock_options', 9.6305853837525035)\n",
      "(False, 'wealth', 8.9660211199691791)\n",
      "(False, 'total_payments', 8.5140956287314875)\n",
      "(False, 'long_term_incentive', 8.1194130541475662)\n",
      "(False, 'deferred_income', 7.9221360027191352)\n",
      "(False, 'restricted_stock', 7.5855209858935693)\n",
      "(False, 'loan_advances', 6.7057870201376479)\n",
      "(False, 'expenses', 3.8744660455757707)\n",
      "(False, 'other', 2.9463988912624939)\n",
      "(False, 'restricted_stock_deferred', 0.71324401933397774)\n",
      "(False, 'fraction_from_poi', 0.37577092640120102)\n",
      "(False, 'deferral_payments', 0.019933736026878885)\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.95      0.93        43\n",
      "        1.0       0.33      0.20      0.25         5\n",
      "\n",
      "avg / total       0.85      0.88      0.86        48\n",
      "\n",
      "\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, my_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "select = SelectKBest()\n",
    "# pca = PCA(n_components = 7)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "steps = [('feature_selection', select),\n",
    "        ('random_forest', clf)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# d_features = pca.fit_transform(features_train)\n",
    "# ds_features = pca.transform(features_test)\n",
    "\n",
    "### and print the report\n",
    "parameters = dict(feature_selection__k = [3,4,5],\n",
    "                  random_forest__n_estimators=[50, 100, 200],\n",
    "                  random_forest__min_samples_split=[2, 3, 4, 5, 10])\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters)\n",
    "\n",
    "### fit your pipeline on features_train and labels_train\n",
    "cv.fit(features_train, labels_train)\n",
    "\n",
    "### call pipeline.predict() on your features_test data to make a set of test predictions\n",
    "pred = cv.predict(features_test)\n",
    "\n",
    "### test your predictions using sklearn.classification_report()\n",
    "report = classification_report(labels_test, pred)\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "\n",
    "results = pandas.DataFrame.from_dict(cv.cv_results_)\n",
    "\n",
    "results_list = zip(cv.best_estimator_.named_steps['feature_selection'].get_support(), my_features[1:],\n",
    "                   cv.best_estimator_.named_steps['feature_selection'].scores_)\n",
    "\n",
    "results_list = sorted(results_list, key = lambda x: x[2], reverse=True)\n",
    "\n",
    "print(cv.best_estimator_)\n",
    "\n",
    "best_scores = cv.best_estimator_.named_steps['feature_selection'].scores_\n",
    "best_scores = sorted([round(x, 3) for x in best_scores], reverse = True)\n",
    "\n",
    "# print best_scores\n",
    "for i in results_list: print i\n",
    "print '\\n',cv.best_estimator_.steps[1][1]\n",
    "print'\\n',report\n",
    "print'\\n',accuracy\n",
    "# print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'bonus', 29.081491199795181)\n",
      "(True, 'salary', 15.119692725298126)\n",
      "(True, 'fraction_to_poi', 12.89761482372556)\n",
      "(False, 'total_stock_value', 10.374045713087989)\n",
      "(False, 'shared_receipt_with_poi', 9.8582776246375587)\n",
      "(False, 'exercised_stock_options', 9.6305853837525035)\n",
      "(False, 'wealth', 8.9660211199691791)\n",
      "(False, 'total_payments', 8.5140956287314875)\n",
      "(False, 'long_term_incentive', 8.1194130541475662)\n",
      "(False, 'deferred_income', 7.9221360027191352)\n",
      "(False, 'restricted_stock', 7.5855209858935693)\n",
      "(False, 'loan_advances', 6.7057870201376479)\n",
      "(False, 'expenses', 3.8744660455757707)\n",
      "(False, 'other', 2.9463988912624939)\n",
      "(False, 'restricted_stock_deferred', 0.71324401933397774)\n",
      "(False, 'fraction_from_poi', 0.37577092640120102)\n",
      "(False, 'deferral_payments', 0.019933736026878885)\n",
      "\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "0.875\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.98      0.93        43\n",
      "        1.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.80      0.88      0.84        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = featureFormat(my_dataset, my_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "select = SelectKBest()\n",
    "# pca = PCA(n_components = 7)\n",
    "clf = SVC()\n",
    "\n",
    "steps = [('feature_selection', select),\n",
    "        ('svc', clf)]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "d_features = pca.fit_transform(features_train)\n",
    "ds_features = pca.transform(features_test)\n",
    "\n",
    "### print the report\n",
    "parameters = dict(feature_selection__k = [3,4,5],\n",
    "                  svc__kernel = [\"rbf\", \"linear\"],\n",
    "                  svc__C = [1, 10, 50, 100, 200])\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters, cv = 10)\n",
    "\n",
    "### fit pipeline on features_train and labels_train\n",
    "cv.fit(features_train, labels_train)\n",
    "\n",
    "### call pipeline.predict() on your features_test data to make a set of test predictions\n",
    "pred = cv.predict(features_test)\n",
    "\n",
    "### test predictions using sklearn.classification_report()\n",
    "report = classification_report( labels_test, pred)\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "\n",
    "results = pandas.DataFrame.from_dict(cv.cv_results_)\n",
    "\n",
    "results_list = zip(cv.best_estimator_.named_steps['feature_selection'].get_support(), my_features[1:],\n",
    "                   cv.best_estimator_.named_steps['feature_selection'].scores_)\n",
    "\n",
    "results_list = sorted(results_list, key = lambda x: x[2], reverse=True)\n",
    "\n",
    "# print(cv.best_estimator_)\n",
    "\n",
    "best_scores = cv.best_estimator_.named_steps['feature_selection'].scores_\n",
    "best_scores = sorted([round(x, 3) for x in best_scores], reverse = True)\n",
    "\n",
    "# print best_scores\n",
    "for i in results_list: print i\n",
    "print '\\n', cv.best_estimator_.steps[1][1]\n",
    "print '\\n', accuracy\n",
    "print '\\n', report\n",
    "\n",
    "# print results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## giving preference to recall over precision hence SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_features = features_list + ['fraction_to_poi','salary','bonus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.86666667  0.82758621  0.86206897  0.89285714  0.89285714]\n",
      "\n",
      "0.868407224959\n",
      "\n",
      "Accuracy: 0.868421052632\n",
      "\n",
      "Report:              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.98      0.93        66\n",
      "        1.0       0.50      0.10      0.17        10\n",
      "\n",
      "avg / total       0.83      0.87      0.83        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C = 10, kernel = 'rbf')\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.525, random_state=42)\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "report = classification_report(labels_test, pred)\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, features, labels, cv = 5)\n",
    "\n",
    "print '\\n', scores\n",
    "print '\\n', scores.mean()\n",
    "\n",
    "print '\\n', \"Accuracy:\", accuracy\n",
    "print '\\n', \"Report:\", report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, my_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
