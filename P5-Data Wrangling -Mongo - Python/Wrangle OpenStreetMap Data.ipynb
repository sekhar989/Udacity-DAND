{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling OpenStreetMap Data of Kolkata, West Bengal, India\n",
    "- by Krishnendu S. Kar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Area of study**: \n",
    "  **City**: [Kolkata](https://www.openstreetmap.org/node/245707150)\n",
    "\n",
    "**Objective**: Audit and clean the data set, converting it from XML to JSON format and load it to MongoDB.\n",
    "\n",
    "**References**:\n",
    "- Lesson 6 from Udacity course, “Data Wrangling with MongoDB”\n",
    "- [Python 're' - documentation](https://docs.python.org/2.6/library/re.html)\n",
    "- [Python 'strip' - documentation](https://docs.python.org/2/library/stdtypes.html?highlight=strip#str.strip)\n",
    "- [MongoDB data import from JSON file](https://docs.mongodb.com/manual/reference/program/mongoimport/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data\n",
    "\n",
    "The data was extracted from the [Overpass API](http://overpass-api.de/query_form.html), by passing the below query:\n",
    "```sql\n",
    "(\n",
    "   node(22.4678, 88.3309, 22.6039, 88.4035);\n",
    "   <;\n",
    ");\n",
    "out meta;\n",
    "```\n",
    "\n",
    "### Tags\n",
    "\n",
    "`iterparse.py` was used to count occurrences of each tag, with a result:\n",
    "\n",
    "```json\n",
    "{'member': 4437,\n",
    " 'meta': 1,\n",
    " 'nd': 861202,\n",
    " 'node': 692730,\n",
    " 'note': 1,\n",
    " 'osm': 1,\n",
    " 'relation': 763,\n",
    " 'tag': 159164,\n",
    " 'way': 148337}\n",
    "```\n",
    "Further modifications were made to `iterparse.py` to examine the keys stored in each `tag` element, in the `k` attribute. Few of the most :\n",
    "\n",
    "```tuple\n",
    "('building', 130748), ('highway', 13468), ('name', 3960), ('landuse', 1542), ('service', 1200), ('type', 762), ('railway', 708), ('natural', 561), ('amenity', 511), ('oneway', 342), ('leisure', 331), ('voltage', 267), ('electrified', 264), ('frequency', 262), ('gauge', 260), ('bridge', 241), ('layer', 212), ('addr:street', 204), ('addr:housenumber', 190), ('ref', 147), ('addr:postcode', 139), ('passenger_lines', 129), ('source', 128), ('name:en', 123), ('lanes', 112), ('addr:city', 106), ('public_transport', 106)\n",
    "```\n",
    "Further parsing was done through the 'tag'-data and a sample of 15 data points were taken for each tag(key, value).\n",
    "\n",
    "Inconcistencies were noticed in:\n",
    "\n",
    "### 1. Postcodes/Zip-Codes\n",
    "Postcodes/Zip-codes were present under *`addr:postcode`* tag. Kolkata postcodes are of 6-digits and ranges from *`700001`* to *`700120`*.\n",
    "While checking the data, several inconsistencies were noticed in the postcodes present in the raw dataset. e.g.: ***`7017`*** (less than 6-digits), ***`'700 073'`***, ***`'7000 026'`***.\n",
    "\n",
    "### 2. Phone Numbers\n",
    "Phone numbers were present under ***`phone`***. Issues viz. ***`+91906285598`***, ***`033 2227 2625`***.\n",
    "***`+91`*** & gaps along with dash(-) should be removed from phone numbers\n",
    "\n",
    "\n",
    "### 3. Street Names\n",
    "There were inconsistencies with street name abbreviations.Issues in Streets viz. ***`Rameswar Shaw Rd`*** , ***`Karbala Tank Ln`***. Acronyms like ***`Rd`*** & ***`Ln`*** are used, which are actually ***`Road`*** & ***`Lane`***.\n",
    "\n",
    "In depth studies related to isseues were made using the *`audit_db.py`* program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Special Tags\n",
    "There were quite a number of `tag k-v pairs`, which are present only once. \n",
    "They are some special tags, which came into the picture just for a specific scenario.\n",
    "e.g.: ***`toilets:disposal`***, ***`name:ml`***, ***`name:hr`*** etc.\n",
    "\n",
    "As part of the cleaning process, a manual selection of `tag k-v pairs` was made based on the amount of occurence.\n",
    "Tags which have occured less than equal to 4-times, were ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MongoDB\n",
    "The json output file was loaded to a mongoDB database using the terminal command shown below.\n",
    "\n",
    "```terminal\n",
    "$: mongoimport --db cities --collection kolkata --type json --file ~/'Udacity DAND'/Calcutta.osm.json\n",
    "\n",
    "2017-08-25T03:06:18.648+0530\tconnected to: localhost\n",
    "2017-08-25T03:06:21.646+0530\t[........................] cities.kolkata\t6.34MB/173MB (3.7%)\n",
    "2017-08-25T03:06:24.646+0530\t[#.......................] cities.kolkata\t13.9MB/173MB (8.0%)\n",
    "2017-08-25T03:06:27.646+0530\t[##......................] cities.kolkata\t21.5MB/173MB (12.4%)\n",
    "2017-08-25T03:06:30.646+0530\t[####....................] cities.kolkata\t29.2MB/173MB (16.9%)\n",
    "2017-08-25T03:06:33.646+0530\t[#####...................] cities.kolkata\t36.3MB/173MB (21.0%)\n",
    "2017-08-25T03:06:36.646+0530\t[######..................] cities.kolkata\t43.8MB/173MB (25.3%)\n",
    "2017-08-25T03:06:39.646+0530\t[#######.................] cities.kolkata\t51.5MB/173MB (29.7%)\n",
    "2017-08-25T03:06:42.646+0530\t[########................] cities.kolkata\t59.3MB/173MB (34.3%)\n",
    "2017-08-25T03:06:45.646+0530\t[#########...............] cities.kolkata\t67.1MB/173MB (38.7%)\n",
    "2017-08-25T03:06:48.646+0530\t[##########..............] cities.kolkata\t74.6MB/173MB (43.1%)\n",
    "2017-08-25T03:06:51.646+0530\t[###########.............] cities.kolkata\t82.3MB/173MB (47.5%)\n",
    "2017-08-25T03:06:54.646+0530\t[############............] cities.kolkata\t90.3MB/173MB (52.1%)\n",
    "2017-08-25T03:06:57.646+0530\t[#############...........] cities.kolkata\t97.5MB/173MB (56.3%)\n",
    "2017-08-25T03:07:00.646+0530\t[##############..........] cities.kolkata\t105MB/173MB (60.6%)\n",
    "2017-08-25T03:07:03.646+0530\t[###############.........] cities.kolkata\t113MB/173MB (65.2%)\n",
    "2017-08-25T03:07:06.646+0530\t[################........] cities.kolkata\t120MB/173MB (69.5%)\n",
    "2017-08-25T03:07:09.646+0530\t[#################.......] cities.kolkata\t128MB/173MB (74.1%)\n",
    "2017-08-25T03:07:12.646+0530\t[##################......] cities.kolkata\t137MB/173MB (78.9%)\n",
    "2017-08-25T03:07:15.646+0530\t[####################....] cities.kolkata\t146MB/173MB (84.0%)\n",
    "2017-08-25T03:07:18.646+0530\t[#####################...] cities.kolkata\t154MB/173MB (89.1%)\n",
    "2017-08-25T03:07:21.646+0530\t[######################..] cities.kolkata\t161MB/173MB (92.7%)\n",
    "2017-08-25T03:07:24.646+0530\t[#######################.] cities.kolkata\t169MB/173MB (97.7%)\n",
    "2017-08-25T03:07:26.057+0530\t[########################] cities.kolkata\t173MB/173MB (100.0%)\n",
    "\n",
    "2017-08-25T03:07:26.057+0530\timported 841067 documents\n",
    "```\n",
    "\n",
    "File sizes:\n",
    "- `Calcutta.osm: 156.9 MB`\n",
    "- `Calcutta.osm.json: 181.6 MB`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Checking total number of documents:\n",
    "\n",
    "```python\n",
    "> db.kolkata.find().count()\n",
    "```\n",
    "Output: 1682134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total `\"node\"` count:\n",
    "```python\n",
    "> db.kolkata.find({\"type\":\"node\"}).count()\n",
    "```\n",
    "Output: 1385460"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total `\"way\"` count:\n",
    "```python\n",
    "> db.kolkata.find({\"type\":\"way\"}).count()\n",
    "```\n",
    "Output: 148337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of unique users:\n",
    "```python\n",
    "> x = db.kolkata.distinct(\"created.user\")\n",
    "> print len(x)\n",
    "```\n",
    "Output: 314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total entries having an address:\n",
    "```python\n",
    "> db.kolkata.find({\"address\" : {\"$exists\" : 1}}).count()\n",
    "```\n",
    "Output: 478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more queries were made, using the `mongodb_queries.py` program. The ouput are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 users with higherst contribution...\n",
    "```json\n",
    "{'$group': {'_id': '$created.user','count': {'$sum': 1}}}, {'$sort': {'count': -1}}, {'$limit': 5}\n",
    "\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```json\n",
    " {u'_id': u'Rondon237', u'count': 147882},\n",
    " {u'_id': u'pvprasad', u'count': 138692},\n",
    " {u'_id': u'hareesh11', u'count': 128650},\n",
    " {u'_id': u'rajureddyvudem', u'count': 127720},\n",
    " {u'_id': u'udaykanth', u'count': 109344}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of users, who contributed the least... \n",
    "```json\n",
    "{'$group': {'_id': '$created.user','count': {'$sum': 1}}}, {'$group': {'_id': '$count','num_users': {'$sum': 1}}}, {'$sort': {'_id': 1}}, {'$limit': 1}\n",
    "```\n",
    "\n",
    "\n",
    "Output:\n",
    "```json\n",
    "{u'_id': 2, u'num_users': 76}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The queries were conducted mostly on the users. It is also noticed that there are very few nodes with actual address. The raw-data is extracted here only from one source, hence further raw-data collection from different sources are recommended.\n",
    "\n",
    "I believe, there are still few opportunities for cleaning and validation of data, which is left unexplored. Keeping that in mind, I would like to state that the data set was well-cleaned for the purposes of this exercise.\n",
    "\n",
    "#### Files\n",
    "- `subset.py`: Creates data subset\n",
    "- `iterparse.py`: Parsing through the dataset and getting an initial idea of the raw dataset\n",
    "- `audit_db.py`: Auditing the identified issues\n",
    "- `final_db_data.py`: Parsing, Editing & Cleaning the identified/considered flaws and dumping a <file>.json file.\n",
    "- `mongodb_queries.py`: Creating basic queries over the database after moving the json data to mongodb database.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
